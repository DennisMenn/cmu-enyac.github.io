{
	"title": "Solving the Non-Volatile Memory Conundrum for Deep Learning Workloads",
    "picture": "./img/isca_workshop_18.png",
	"content": "There is an on-going debate regarding whether and how emerging non-volatile memory (NVM) technologies can be used for data-intensive applications, particularly for deep learning workloads. NVM has been extensively studied in recent years. However, those studies rely on cycle-accurate architectural simulators since NVM is not available in platforms for commercial use. In this work, we show real platform measurements for memory footprint of various deep neural network workloads by using Caffe framework on a high-end NVIDIA Titan X GPU for ImageNet dataset. Our results show that NVM can be a promising solution for data-intensive applications in certain cases. Our thorough analysis show the cases where we would gain advantage of using NVM compared to conventional memory technologies such as SRAM. This work is a roadmap for both computer architecture and device technology areas as our analysis relies on actual platform, fine-grain measurements.<br>Click <a href=\"http://acs.ict.ac.cn/asbd2018/slides/AI_ASBD.pdf\">here</a> for the paper."
}